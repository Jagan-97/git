{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPz9+X5duLHDO5NIPLW1H7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jagan-97/git/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i2bJTy253931",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6065427-130f-4ca9-b2d4-74c667de321a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector 1: [1. 2. 3.]\n",
            "Vector 2: [1. 2. 3.]\n",
            "Result of Vector addition: [5. 7. 9.]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "vector1 =tf.constant([1,2,3], dtype=tf.float32, name='vector1')\n",
        "vector2 =tf.constant([4,5,6], dtype=tf.float32, name='vector2')\n",
        "\n",
        "result = vector1 + vector2\n",
        "\n",
        "print(\"Vector 1:\", vector1.numpy())\n",
        "print(\"Vector 2:\", vector1.numpy())\n",
        "print(\"Result of Vector addition:\", result.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Flatten the images (convert 28x28 images into 1D arrays)\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Step 2: Build the feed-forward neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"\\nAccuracy on Test Set:\", accuracy)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCANs8t_68Hp",
        "outputId": "474c51a0-97c0-4254-fefe-087b32509cd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 6s 6ms/step - loss: 0.3046 - accuracy: 0.9133 - val_loss: 0.1461 - val_accuracy: 0.9595\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1212 - accuracy: 0.9642 - val_loss: 0.1354 - val_accuracy: 0.9584\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.0837 - accuracy: 0.9746 - val_loss: 0.0974 - val_accuracy: 0.9718\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0640 - accuracy: 0.9797 - val_loss: 0.1054 - val_accuracy: 0.9704\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.0937 - val_accuracy: 0.9711\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.0890 - val_accuracy: 0.9744\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.0966 - val_accuracy: 0.9732\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.0871 - val_accuracy: 0.9783\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0938 - val_accuracy: 0.9760\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1109 - val_accuracy: 0.9737\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9741\n",
            "\n",
            "Accuracy on Test Set: 0.9740999937057495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Step 2: Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"\\nAccuracy on Test Set:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4qbpLjQCgmA",
        "outputId": "c34024d4-931f-4090-b5f7-822149e6abec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 60s 94ms/step - loss: 1.6197 - accuracy: 0.4065 - val_loss: 1.4106 - val_accuracy: 0.4856\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 55s 88ms/step - loss: 1.2758 - accuracy: 0.5429 - val_loss: 1.1961 - val_accuracy: 0.5826\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 55s 89ms/step - loss: 1.1371 - accuracy: 0.5962 - val_loss: 1.1059 - val_accuracy: 0.6158\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 55s 88ms/step - loss: 1.0382 - accuracy: 0.6328 - val_loss: 1.0525 - val_accuracy: 0.6367\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 54s 86ms/step - loss: 0.9562 - accuracy: 0.6646 - val_loss: 0.9695 - val_accuracy: 0.6598\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 55s 88ms/step - loss: 0.8983 - accuracy: 0.6837 - val_loss: 0.9765 - val_accuracy: 0.6585\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 57s 90ms/step - loss: 0.8393 - accuracy: 0.7064 - val_loss: 0.9415 - val_accuracy: 0.6782\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 56s 89ms/step - loss: 0.8021 - accuracy: 0.7184 - val_loss: 0.9018 - val_accuracy: 0.6910\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 56s 89ms/step - loss: 0.7521 - accuracy: 0.7363 - val_loss: 0.9048 - val_accuracy: 0.6923\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 54s 87ms/step - loss: 0.7199 - accuracy: 0.7462 - val_loss: 0.8844 - val_accuracy: 0.6957\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.8920 - accuracy: 0.6918\n",
            "\n",
            "Accuracy on Test Set: 0.6917999982833862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Build the CNN model with Batch Normalization and Dropout\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
        "          epochs=30, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"\\nAccuracy on Test Set:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQe9cZ0ME9YU",
        "outputId": "cb519a9d-ad8a-4575-cf34-6ae5edd356af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 120s 151ms/step - loss: 1.8074 - accuracy: 0.3636 - val_loss: 1.4442 - val_accuracy: 0.4788\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 118s 150ms/step - loss: 1.4388 - accuracy: 0.4859 - val_loss: 1.3392 - val_accuracy: 0.5189\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 119s 152ms/step - loss: 1.2888 - accuracy: 0.5431 - val_loss: 1.2110 - val_accuracy: 0.5566\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 119s 152ms/step - loss: 1.2005 - accuracy: 0.5785 - val_loss: 1.0878 - val_accuracy: 0.6259\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 122s 156ms/step - loss: 1.1251 - accuracy: 0.6057 - val_loss: 1.0680 - val_accuracy: 0.6375\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 118s 151ms/step - loss: 1.0840 - accuracy: 0.6215 - val_loss: 1.7770 - val_accuracy: 0.4720\n",
            "Epoch 7/30\n",
            "303/782 [==========>...................] - ETA: 1:10 - loss: 1.0411 - accuracy: 0.6374"
          ]
        }
      ]
    }
  ]
}